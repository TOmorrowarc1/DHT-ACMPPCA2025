# 分布式哈希表报告
### 一、分布式哈希表概念与问题分析
分布式哈希表是在分布式系统上对哈希表的接口进行实现的程序。

哈希表在全表中储存多个key-value键值对，其接口如下：  
1.查询：  
输入key，返回<bool,value>对。  
依照给出的key，查询对应的value，如果存在则返回<true,value>，不存在则返回<false,null>。  
2.插入：  
输入<key,value>对，返回bool值。  
如果key不存在则插入成功，如果key已经存在则更改对应value值。   
3.删除
输入key，返回bool值。  
如果<key,value>存在则将其从表中删除，同时返回true，若不存在则返回false。  

分布式系统是多个通过网络通信的计算机构成的系统。在DHT中，每一个计算机都支持哈希表的接口，
每个计算机被称为系统的一个节点。

DHT不同于一般哈希表之处乃分布式系统每一个节点都只有全局信息的一部分信息：其中一个节点只能储存一部分的<key,value>对，只知晓当前系统中一部分进程的情况，甚至其他节点的地址也未必清晰。因此，DHT的实现中主要需克服以下困难：   
1.使用所在节点的部分信息获得需要的信息；  
2.分布式系统可能存在节点的加入与离开；  
3.分布式系统中每个节点，每条链接都可能出现错误，对可靠性与鲁棒性提出很高要求。  
这三个问题对应着DHT实现的三个关键点：路由算法，可扩展性，可靠性，而后两者在实现上围绕第一点存在————只要保证按照路由算法能获得正确的信息，DHT就能够正常工作，因此处理节点出入与错误的措施必然旨归于保证路由算法的正确性。

### 二、协议：问题解决方案
本项目使用Chord与Kademila协议解决上文提出的问题。两者具有相似的特征：皆为去中心化协议，即每个节点执行同样的行为就能实现最后整体的DHT系统行为；采取类似的路由措施，使用一个universal hash function，将所有节点的地址与key的地址映射至抽象的拓扑空间，在对应的拓扑结构而非实际网络结构中进行路由。  
#### 1.Chord协议
1.1 路由算法  
在Chord协议中，每一个节点与键值对被分配唯一确定的地址值：节点的地址为其网络地址，<key,value>的地址为key的值。该值经过哈希算法映射到一个足够大的整数（本实现中为ull）作为对象的拓扑地址，对象的拓扑地址之间存在严谨的大小序结构，因此在头尾接续的情况下可以依据序结构形成一个巨大的环，该环即为Chord拓扑结构的整个地址空间。规定顺时针方向上拓扑地址逐渐增大，首尾相接处除外。每个节点与键值对都在环上占据对应的位置，称某个对象的顺时针方向上的第一个节点为该对象的后继节点，逆时针方向上的第一个节点为其前继节点。 

Chord规定：   
01 每一个键值对都储存在其后继节点中。  
02 每一个节点都要储存其后继节点的实际地址，称为其后继指针。

只要保证以上两条性质，Chord协议就能够支持DHT的所有接口。以下为Chord的naive路由算法以及该结论的证明：   
Chord协议中每个节点能够实现如下路由函数：   
01 find_predecessor: 根据本节点地址，后继节点地址值判断是否本节点为键值对的前继，即是否key的拓扑地址在两个节点之间。若不是，则移动至其后继节点。重复相同函数，最终返回key的前继节点地址。  
02 find_successor: 找到前继后查询其后继。如是路由成功。  

但是这种寻址方法的时间复杂度为$O(n)$（$n$为节点个数），过高。可以使用如下方式优化：利用倍增的思想，每个节点多储存一个finger table，其中table[i]存储地址$self+2^i$的后继节点（其中self为自身地址）。如此可以改进find_predecessor函数：  
从i=63开始递减遍历，直到第一个节点地址在键值对与当前节点之间，返回该地址。  
在手指表可靠的情况下，查询复杂度降低为$O(logn)$，因为每一次查询中剩余的节点至目标后继节点的距离都会至少被削减一半。当然，即使手指表内容有误也不会导致结果的错误，因为 find_predecessor 始终保证查询到节点在当前节点与键值对之间，在后继指针无误的情况下不会寻找到错误的前继。

1.2 可扩展性：节点加入与离开  
在某个节点加入Chord时，维护Chord的基本性质需要完成如下内容：确定该节点后继以及改变其前继节点后继指针，同时将该节点后继中理应存储于该节点的部分键值对移动到该节点。完成前半部分需要为每一个节点引入前继指针，即每个节点要多储存前继的地址。至此，一个Chord节点的结构已经完成：储存自身地址，前继地址，后继地址与手指表作为拓扑结构的信息，储存本节点负责的键值对。   
在一个新节点B插入时，首先调用find_successor找到该节点后继C，并将B的后继指针指向C，C的前继调整为B，同时遍历C中键值对，将B负责的部分移动到B中。值得注意的是，C原先的前继节点A的后继指针需要调整，我们可以显式的在插入时调整，也可以依赖于Chord的另一设计，也是DHT协议中的常见idea：stablize协议，即在后台作为background thread不断运行的维稳机制。其分布设计目的在于处理分布式系统固有的不稳定性：我们永远不知道是否会有节点突然下线，是否会有节点突然出现，前继指针是否会突然偏移等。最稳妥的思路不是保证没有错误发生，而是给予整个系统不断自我恢复的能力。   
Chord的stablize协议的第一部分负责前继与后继的维护：每隔一段时间，X节点向其后继Y节点发报，通知Y节点“X节点认为Y是其后继”，Y检查自身记录前继是否为X，若是则检测未发现问题；若不是，则检测其前继$X'$是否地址在X与Y之间，不在或$X'$为空则调整Y的前继为X，在则调整X的后继为$X'$并再次重复此过程。这一过程可以保证节点之间的前后继关系能够自洽成环。第二部分保证前继的有效性，每隔一段时间向前继发送心跳包，未回应则将前继置空。前两部分保证节点构成的拓扑结构稳定有序符合要求。第三部分负责手指表的维护，每隔一段时间随机发起一次查询，更新table[i]处节点地址。该部分主要保证手指表中节点活性与查询速度。   
节点退出时需要通知前继维护拓扑结构，同时将自身存储的数据转移到后继中存储。

1.3 可靠性（available）  
在本次实现中，要应对的分布式系统故障即超出接口规定的操作只有一条：节点的突然下线(force quit)，节点强制下线会带来结构与数据两方面的问题：拓扑结构出现断点，数据出现丢失。这对Chord每个节点中存储的信息提出更高的要求：每个节点必须在其后继下线后能够联系到某个后继（完全断开的拓扑环无法修复）；每个节点存储数据必须有至少一份副本（永久丢失的数据无法找回）。因此对Chord的一个节点的结构进行再一次拓展，引入后继列表，其中存储直接后继，第二个后继等共计$\alpha$个后继，数目由对鲁棒性的要求决定。
Stablize协议使用新引入的数据保证Chord的性质，对应第一部分的更新与该协议的第四个部分：副本推送。在第四部分中，每个节点将自身存储数据定时的向后继列表中的节点推送，形成对应个数的副本。在第一部分中每个节点维护的不再只是后继而是整个后继列表，每隔一段时间遍历整个后继，如果出现后继的丢失则将下一个后继索引-1并补全整个列表，始终保持记录后继的个数。同时将丢失的后继视为下线，同时合并副本，如A的后继为B,C,D,E,F，A检测时发现C,D消失，则通知E将C,D的副本合并进自己的内容。  
以上就是Chord的全部实现内容，合适的路由算法，节点插入退出处置以及强大的Stablize协议保证其正确性与高性能。

#### 2.Kademlia协议
2.1